import os
import json
import time
import asyncio
from typing import AsyncGenerator
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import signal
import sys

from config import Config
from llm_client import LLMClient
from embedding_client import EmbeddingClient
from retriever import PaperRetriever
from literature_analyzer import LiteratureAnalyzer
from review_generator import ReviewGenerator
from prompt_template import detect_language


def load_env_file(env_file: str):
    """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶"""
    if not os.path.isabs(env_file):
        current_dir = os.path.dirname(os.path.abspath(__file__))
        env_file = os.path.join(current_dir, env_file)
    
    if os.path.exists(env_file):
        print(f"âœ“ æ‰¾åˆ° .env æ–‡ä»¶: {env_file}")
        loaded_count = 0
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value.strip('"\'')
                    loaded_count += 1
        print(f"âœ“ æˆåŠŸåŠ è½½ {loaded_count} ä¸ªç¯å¢ƒå˜é‡")
        return True
    else:
        print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° .env æ–‡ä»¶: {env_file}")
        return False


# åŠ è½½ç¯å¢ƒå˜é‡
load_env_file(".env")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="ICAIS2025-LiteratureReview API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

@app.middleware("http")
async def simple_log_middleware(request, call_next):
    """ç®€åŒ–çš„æ—¥å¿—ä¸­é—´ä»¶"""
    start_time = time.time()
    path = request.url.path
    
    if not path.startswith("/health"):
        print(f"ğŸ“¥ [{time.strftime('%H:%M:%S')}] {request.method} {path}")
    
    try:
        response = await call_next(request)
        process_time = time.time() - start_time
        if not path.startswith("/health"):
            print(f"ğŸ“¤ [{time.strftime('%H:%M:%S')}] {request.method} {path} - {response.status_code} ({process_time:.3f}s)")
        return response
    except Exception as e:
        print(f"âŒ [{time.strftime('%H:%M:%S')}] é”™è¯¯: {request.method} {path} - {e}")
        raise

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# è®¾ç½®å…¨å±€è¶…æ—¶
REQUEST_TIMEOUT = Config.LITERATURE_REVIEW_TIMEOUT


class LiteratureReviewRequest(BaseModel):
    query: str


def format_sse_data(content: str) -> str:
    """ç”ŸæˆOpenAIæ ¼å¼çš„SSEæ•°æ®"""
    data = {
        "object": "chat.completion.chunk",
        "choices": [{
            "delta": {
                "content": content
            }
        }]
    }
    return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"


def format_sse_done() -> str:
    """ç”ŸæˆSSEç»“æŸæ ‡è®°"""
    return "data: [DONE]\n\n"


def stream_message(message: str, chunk_size: int = 1):
    """å°†æ¶ˆæ¯æŒ‰å­—ç¬¦æµå¼è¾“å‡ºï¼ˆåŒæ­¥ç”Ÿæˆå™¨ï¼‰"""
    for i in range(0, len(message), chunk_size):
        chunk = message[i:i + chunk_size]
        yield format_sse_data(chunk)


async def run_with_heartbeat(task_func, *args, heartbeat_interval=25, **kwargs):
    """
    æ‰§è¡Œé•¿æ—¶é—´ä»»åŠ¡ï¼ŒæœŸé—´å®šæœŸå‘é€å¿ƒè·³æ•°æ®
    
    Args:
        task_func: è¦æ‰§è¡Œçš„åŒæ­¥å‡½æ•°
        *args, **kwargs: ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°
        heartbeat_interval: å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤25ç§’
    
    Yields:
        å¿ƒè·³æ•°æ®ï¼ˆç©ºæ ¼å­—ç¬¦ï¼‰æˆ–ä»»åŠ¡ç»“æœ
    """
    start_time = time.time()
    last_heartbeat = start_time
    
    # åˆ›å»ºä»»åŠ¡ï¼ˆä½¿ç”¨asyncio.to_threadå°†åŒæ­¥å‡½æ•°è½¬æ¢ä¸ºåç¨‹ï¼‰
    task = asyncio.create_task(asyncio.to_thread(task_func, *args, **kwargs))
    
    # åœ¨ä»»åŠ¡æ‰§è¡ŒæœŸé—´å®šæœŸå‘é€å¿ƒè·³
    while not task.done():
        await asyncio.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
        elapsed = time.time() - last_heartbeat
        
        # å¦‚æœè¶…è¿‡å¿ƒè·³é—´éš”ï¼Œå‘é€å¿ƒè·³æ•°æ®
        if elapsed >= heartbeat_interval:
            yield format_sse_data(" ")  # å‘é€ä¸€ä¸ªç©ºæ ¼ä½œä¸ºå¿ƒè·³
            last_heartbeat = time.time()
        
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
        if task.done():
            break
    
    # ç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶è¿”å›ç»“æœ
    try:
        result = await task
        # ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ¥åŒºåˆ†ç»“æœå’Œå¿ƒè·³æ•°æ®
        yield ("RESULT", result)
    except Exception as e:
        print(f"âš ï¸  ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        raise e


async def _generate_review_internal(query: str) -> AsyncGenerator[str, None]:
    """å†…éƒ¨ç”Ÿæˆå™¨å‡½æ•°ï¼Œæ‰§è¡Œå®é™…çš„æ–‡çŒ®ç»¼è¿°ç”Ÿæˆé€»è¾‘"""
    start_time = time.time()
    
    try:
        # å…ˆæ£€æµ‹è¯­è¨€ï¼Œç”¨äºåç»­æ¶ˆæ¯æ¨¡æ¿
        language = await asyncio.to_thread(detect_language, query)
        
        # æ ¹æ®è¯­è¨€è®¾ç½®æ¶ˆæ¯æ¨¡æ¿
        if language == 'zh':
            msg_templates = {
                'step1': "### ğŸ“ æ­¥éª¤ 1/6: å…³é”®è¯æå–ä¸é¢†åŸŸåˆ†æ\n\nâœ… å·²å®Œæˆ\n\n",
                'step2': lambda n: f"### ğŸ“š æ­¥éª¤ 2/6: æ··åˆæ£€ç´¢è®ºæ–‡\n\nâœ… å·²æ£€ç´¢åˆ° {n} ç¯‡ç›¸å…³è®ºæ–‡\n\n",
                'step3': "### ğŸ—‚ï¸ æ­¥éª¤ 3/6: è®ºæ–‡åˆ†ç±»ä¸ç­›é€‰\n\nâœ… å·²å®Œæˆ\n\n",
                'step4': "### ğŸ“„ æ­¥éª¤ 4/6: è®ºæ–‡å†…å®¹æ€»ç»“\n\n",
                'step5': "### ğŸ” æ­¥éª¤ 5/6: ä¸»é¢˜èšç±»ä¸è¶‹åŠ¿åˆ†æ\n\n",
                'step6': "### ğŸ“‹ æ­¥éª¤ 6/6: ç”Ÿæˆæ–‡çŒ®ç»¼è¿°\n\n",
                'final_title': "## ğŸ“„ æ–‡çŒ®ç»¼è¿°\n\n",
                'error_no_papers': "## âŒ é”™è¯¯\n\næœªæ£€ç´¢åˆ°ç›¸å…³è®ºæ–‡ï¼Œç¨‹åºç»ˆæ­¢\n\n",
                'error_config': "## âŒ é”™è¯¯\n\né…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®\n\n",
                'error_config_exception': lambda e: f"## âŒ é”™è¯¯\n\né…ç½®éªŒè¯å¼‚å¸¸: {e}\n\n",
                'error_llm_init': lambda e: f"## âŒ é”™è¯¯\n\nLLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}\n\n",
                'error_embedding_init': lambda e: f"## âŒ é”™è¯¯\n\nEmbeddingå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}\n\n",
                'error_retriever_init': lambda e: f"## âŒ é”™è¯¯\n\nè®ºæ–‡æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}\n\n",
                'error_timeout': lambda t: f"## âŒ è¶…æ—¶é”™è¯¯\n\nè¯·æ±‚å¤„ç†è¶…è¿‡ {t} ç§’ï¼Œå·²è‡ªåŠ¨ç»ˆæ­¢\n\n",
                'error_general': lambda e: f"## âŒ é”™è¯¯\n\nç¨‹åºæ‰§è¡Œå¤±è´¥: {e}\n\n"
            }
        else:
            msg_templates = {
                'step1': "### ğŸ“ Step 1/6: Keyword Extraction and Domain Analysis\n\nâœ… Completed\n\n",
                'step2': lambda n: f"### ğŸ“š Step 2/6: Hybrid Paper Retrieval\n\nâœ… Retrieved {n} related papers\n\n",
                'step3': "### ğŸ—‚ï¸ Step 3/6: Paper Classification and Filtering\n\nâœ… Completed\n\n",
                'step4': "### ğŸ“„ Step 4/6: Paper Content Summarization\n\n",
                'step5': "### ğŸ” Step 5/6: Topic Clustering and Trend Analysis\n\n",
                'step6': "### ğŸ“‹ Step 6/6: Literature Review Generation\n\n",
                'final_title': "## ğŸ“„ Literature Review\n\n",
                'error_no_papers': "## âŒ Error\n\nNo related papers found. Process terminated.\n\n",
                'error_config': "## âŒ Error\n\nConfiguration validation failed. Please check environment variables.\n\n",
                'error_config_exception': lambda e: f"## âŒ Error\n\nConfiguration validation exception: {e}\n\n",
                'error_llm_init': lambda e: f"## âŒ Error\n\nLLM client initialization failed: {e}\n\n",
                'error_embedding_init': lambda e: f"## âŒ Error\n\nEmbedding client initialization failed: {e}\n\n",
                'error_retriever_init': lambda e: f"## âŒ Error\n\nPaper retriever initialization failed: {e}\n\n",
                'error_timeout': lambda t: f"## âŒ Timeout Error\n\nRequest processing exceeded {t} seconds. Automatically terminated.\n\n",
                'error_general': lambda e: f"## âŒ Error\n\nProcess execution failed: {e}\n\n"
            }
        
        # éªŒè¯é…ç½®ï¼ˆä¸è¾“å‡ºï¼‰
        try:
            config_valid = await asyncio.to_thread(Config.validate_config)
            if not config_valid:
                for chunk in stream_message(msg_templates['error_config']):
                    yield chunk
                return
        except Exception as e:
            for chunk in stream_message(msg_templates['error_config_exception'](e)):
                yield chunk
            return
        
        # åˆ›å»ºç»„ä»¶ï¼ˆä¸è¾“å‡ºåˆå§‹åŒ–ä¿¡æ¯ï¼‰
        try:
            llm_client = LLMClient()
        except Exception as e:
            for chunk in stream_message(msg_templates['error_llm_init'](e)):
                yield chunk
            return
        
        try:
            embedding_client = EmbeddingClient()
        except Exception as e:
            # Embeddingå®¢æˆ·ç«¯å¤±è´¥ä¸å½±å“ä¸»è¦æµç¨‹ï¼Œåªè®°å½•è­¦å‘Š
            print(f"âš ï¸  Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†è·³è¿‡è¯­ä¹‰é‡æ’åº")
            embedding_client = None
        
        try:
            retriever = PaperRetriever()
        except Exception as e:
            for chunk in stream_message(msg_templates['error_retriever_init'](e)):
                yield chunk
            return
        
        analyzer = LiteratureAnalyzer(llm_client, language=language)
        generator = ReviewGenerator(llm_client, language=language)
        
        # æ­¥éª¤1: å…³é”®è¯æå–ä¸é¢†åŸŸåˆ†æ
        keywords = await asyncio.to_thread(analyzer.extract_keywords, query)
        domain_analysis = await asyncio.to_thread(analyzer.analyze_domain, query, keywords)
        for chunk in stream_message(msg_templates['step1']):
            yield chunk
        
        # æ­¥éª¤2: æ··åˆæ£€ç´¢è®ºæ–‡
        papers = await asyncio.to_thread(retriever.hybrid_retrieve, query, keywords)
        for chunk in stream_message(msg_templates['step2'](len(papers))):
            yield chunk
        
        if not papers:
            for chunk in stream_message(msg_templates['error_no_papers']):
                yield chunk
            return
        
        # æ­¥éª¤3: è®ºæ–‡åˆ†ç±»ä¸ç­›é€‰
        classified_papers = await asyncio.to_thread(analyzer.classify_papers, papers, query)
        for chunk in stream_message(msg_templates['step3']):
            yield chunk
        
        # æ­¥éª¤4: è®ºæ–‡å†…å®¹æ€»ç»“ï¼ˆä½¿ç”¨å¿ƒè·³æœºåˆ¶ï¼‰
        for chunk in stream_message(msg_templates['step4']):
            yield chunk
        
        if language == 'zh':
            step4_progress = "ğŸ”„ æ­£åœ¨æ€»ç»“è®ºæ–‡å†…å®¹ï¼Œè¯·ç¨å€™...\n\n"
        else:
            step4_progress = "ğŸ”„ Summarizing paper content, please wait...\n\n"
        
        for chunk in stream_message(step4_progress):
            yield chunk
        
        summaries = None
        async for item in run_with_heartbeat(
            analyzer.summarize_papers,
            classified_papers, query,
            heartbeat_interval=25
        ):
            if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                summaries = item[1]
                break
            else:
                yield item
        
        if not summaries:
            summaries = []
        
        # æ­¥éª¤5: ä¸»é¢˜èšç±»ä¸è¶‹åŠ¿åˆ†æï¼ˆä½¿ç”¨å¿ƒè·³æœºåˆ¶ï¼‰
        for chunk in stream_message(msg_templates['step5']):
            yield chunk
        
        if language == 'zh':
            step5_progress = "ğŸ”„ æ­£åœ¨è¿›è¡Œä¸»é¢˜èšç±»å’Œè¶‹åŠ¿åˆ†æï¼Œè¯·ç¨å€™...\n\n"
        else:
            step5_progress = "ğŸ”„ Performing topic clustering and trend analysis, please wait...\n\n"
        
        for chunk in stream_message(step5_progress):
            yield chunk
        
        topics = None
        trends = None
        
        async for item in run_with_heartbeat(
            analyzer.cluster_topics,
            summaries,
            heartbeat_interval=25
        ):
            if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                topics = item[1]
                break
            else:
                yield item
        
        async for item in run_with_heartbeat(
            analyzer.analyze_trends,
            classified_papers,
            heartbeat_interval=25
        ):
            if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                trends = item[1]
                break
            else:
                yield item
        
        # æ­¥éª¤6: ç”Ÿæˆæ–‡çŒ®ç»¼è¿°ï¼ˆä½¿ç”¨å¿ƒè·³æœºåˆ¶ï¼‰
        for chunk in stream_message(msg_templates['step6']):
            yield chunk
        
        if language == 'zh':
            step6_progress = "ğŸ”„ æ­£åœ¨ç”Ÿæˆæ–‡çŒ®ç»¼è¿°ï¼Œè¯·ç¨å€™...\n\n"
        else:
            step6_progress = "ğŸ”„ Generating literature review, please wait...\n\n"
        
        for chunk in stream_message(step6_progress):
            yield chunk
        
        review = None
        async for item in run_with_heartbeat(
            generator.generate_review,
            summaries, topics or "", trends or "", query, classified_papers,
            heartbeat_interval=25
        ):
            if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                review = item[1]
                break
            else:
                yield item
        
        # è¾“å‡ºæœ€ç»ˆç»¼è¿°
        if review:
            for chunk in stream_message(msg_templates['final_title']):
                yield chunk
            for chunk in stream_message(review):
                yield chunk
        else:
            if language == 'zh':
                error_msg = "## âŒ é”™è¯¯\n\næ–‡çŒ®ç»¼è¿°ç”Ÿæˆå¤±è´¥\n\n"
            else:
                error_msg = "## âŒ Error\n\nLiterature review generation failed\n\n"
            for chunk in stream_message(error_msg):
                yield chunk
        
    except asyncio.TimeoutError:
        elapsed = time.time() - start_time
        if language == 'zh':
            error_msg = f"## âŒ è¶…æ—¶é”™è¯¯\n\nè¯·æ±‚å¤„ç†è¶…è¿‡ {REQUEST_TIMEOUT} ç§’ï¼Œå·²è‡ªåŠ¨ç»ˆæ­¢\n\n"
        else:
            error_msg = f"## âŒ Timeout Error\n\nRequest processing exceeded {REQUEST_TIMEOUT} seconds. Automatically terminated.\n\n"
        for chunk in stream_message(error_msg):
            yield chunk
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ–‡çŒ®ç»¼è¿°å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        if language == 'zh':
            error_msg = f"## âŒ é”™è¯¯\n\nç¨‹åºæ‰§è¡Œå¤±è´¥: {e}\n\n"
        else:
            error_msg = f"## âŒ Error\n\nProcess execution failed: {e}\n\n"
        for chunk in stream_message(error_msg):
            yield chunk


@app.post("/literature_review")
async def generate_literature_review(request: LiteratureReviewRequest):
    """
    ç”Ÿæˆæ–‡çŒ®ç»¼è¿°
    
    Args:
        request: åŒ…å«ç”¨æˆ·æŸ¥è¯¢çš„è¯·æ±‚
        
    Returns:
        StreamingResponse: SSEæµå¼å“åº”
    """
    try:
        return StreamingResponse(
            _generate_review_internal(request.query),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "ok",
        "service": "ICAIS2025-LiteratureReview API",
        "version": "1.0.0"
    }


@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "service": "ICAIS2025-LiteratureReview API",
        "version": "1.0.0",
        "health": "http://localhost:3000/health",
        "docs": "http://localhost:3000/docs",
        "literature_review": "POST /literature_review"
    }


# ä¼˜é›…å…³é—­å¤„ç†
def shutdown_handler(signum, frame):
    print(f"\nâš ï¸ æ”¶åˆ°ç»ˆæ­¢ä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    sys.exit(0)


signal.signal(signal.SIGINT, shutdown_handler)
signal.signal(signal.SIGTERM, shutdown_handler)

if __name__ == "__main__":
    import uvicorn
    
    # éªŒè¯ç«¯å£å¯ç”¨æ€§
    import socket
    def check_port(port):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            try:
                s.bind(("0.0.0.0", port))
                return True
            except OSError:
                return False
    
    if not check_port(3000):
        print(f"âŒ ç«¯å£3000å·²è¢«å ç”¨ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æœåŠ¡åœ¨ä½¿ç”¨")
        sys.exit(1)
    
    print("ğŸš€ å¯åŠ¨ FastAPI æœåŠ¡...")
    print(f"ğŸ“ ç›‘å¬åœ°å€: http://0.0.0.0:3000")
    print(f"ğŸ“ å¥åº·æ£€æŸ¥: curl http://localhost:3000/health")
    print(f"ğŸ“š APIæ–‡æ¡£: http://localhost:3000/docs")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=3000,
        log_level="info",
        access_log=True,
        reload=False,
        workers=1,
        loop="asyncio",
        timeout_keep_alive=30,
        limit_concurrency=100,
    )

